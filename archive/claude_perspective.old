import cv2
import sys
import numpy as np
import logging
from datetime import datetime

argv = sys.argv
basename=argv[1]
basename=basename.replace(".png", "")
# Setup logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('claude_log.log', mode='w'),
        logging.StreamHandler()
    ]
)
def find_screens_comprehensive(image_path):
    """
    Finds screens using bounding rectangles with extensive debugging.
    Based on the successful gem_perspective.py approach.
    """
    
    # Load the image
    image = cv2.imread(image_path)
    if image is None:
        logging.error(f"Could not load image from {image_path}")
        return []

    img_height, img_width = image.shape[:2]
    logging.info(f"Image loaded: {image_path}, Dimensions: {img_width}x{img_height}")
    
    # Save original
    # cv2.imwrite(f'{basename}_01_original.png', image)
    
    # --- Preprocessing (following gem's successful approach) ---
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    # cv2.imwrite(f'{basename}_02_grayscale.png', gray)
    # logging.info("Saved grayscale image")

    # Try multiple blur kernels
    blurred_7 = cv2.GaussianBlur(gray, (7, 7), 0)
    # cv2.imwrite(f'{basename}_03_blurred_7x7.png', blurred_7)
    
    blurred_5 = cv2.GaussianBlur(gray, (5, 5), 0)
    # cv2.imwrite(f'{basename}_04_blurred_5x5.png', blurred_5)
    
    # --- Edge Detection with multiple thresholds ---
    edge_configs = [
        (30, 100, "gem_like"),  # Like the successful gem script
        (20, 80, "lower"),
        (40, 120, "higher"),
        (15, 50, "very_low"),
        (50, 150, "high")
    ]
    
    all_candidates = []
    candidate_id = 0
    
    for config_idx, (low_thresh, high_thresh, name) in enumerate(edge_configs):
        edges = cv2.Canny(blurred_7, low_thresh, high_thresh)
        cv2.imwrite(f'{basename}_05_edges_{name}.png', edges)
        logging.info(f"Edge detection {name}: Canny({low_thresh}, {high_thresh})")
        
        # Find contours
        contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        logging.info(f"{name}: Found {len(contours)} initial contours")
        
        # Create debug image for this method
        debug_img = image.copy()
        
        for contour_idx, contour in enumerate(contours):
            # Get bounding rectangle
            x, y, w, h = cv2.boundingRect(contour)
            
            # Skip very small contours to reduce noise
            if w < 50 or h < 50:
                continue
            
            # Calculate all metrics
            contour_area = cv2.contourArea(contour)
            hull = cv2.convexHull(contour)
            hull_area = cv2.contourArea(hull)
            solidity = contour_area / float(hull_area) if hull_area > 0 else 0
            
            width_ratio = w / float(img_width)
            height_ratio = h / float(img_height)
            aspect_ratio = w / float(h) if h > 0 else 0
            
            # Perimeter and approximation
            perimeter = cv2.arcLength(contour, True)
            epsilon = 0.02 * perimeter
            approx = cv2.approxPolyDP(contour, epsilon, True)
            num_vertices = len(approx)
            
            # Store candidate info
            candidate = {
                'id': candidate_id,
                'method': name,
                'x': x,
                'y': y,
                'w': w,
                'h': h,
                'width_ratio': width_ratio,
                'height_ratio': height_ratio,
                'aspect_ratio': aspect_ratio,
                'area': contour_area,
                'solidity': solidity,
                'vertices': num_vertices,
                'contour': contour
            }
            
            # Check against gem-like criteria (what worked)
            width_check_gem = (0.15 * img_width) < w < (0.40 * img_width)
            height_check_gem = (0.15 * img_height) < h < (0.43 * img_height)
            aspect_check_gem = 0.8 < aspect_ratio < 2.5
            solidity_check_gem = solidity > 0.60
            
            # Also check more relaxed criteria
            width_check_relaxed = (0.10 * img_width) < w < (0.50 * img_width)
            height_check_relaxed = (0.10 * img_height) < h < (0.50 * img_height)
            aspect_check_relaxed = 0.5 < aspect_ratio < 3.0
            
            # Categorize candidate
            if width_check_gem and height_check_gem and aspect_check_gem:
                candidate['category'] = 'EXCELLENT'
                color = (0, 255, 0)  # Green
                thickness = 3
            elif width_check_relaxed and height_check_relaxed and aspect_check_relaxed:
                candidate['category'] = 'GOOD'
                color = (0, 200, 255)  # Orange
                thickness = 2
            elif width_check_relaxed or height_check_relaxed:
                candidate['category'] = 'PARTIAL'
                color = (255, 200, 0)  # Cyan
                thickness = 1
            else:
                candidate['category'] = 'POOR'
                color = (128, 128, 128)  # Gray
                thickness = 1
            
            # Log all candidates with details
            if w > 100 and h > 100:  # Only log significant sizes
                logging.info(f"Candidate #{candidate_id} [{name}]:")
                logging.info(f"  Position: ({x}, {y})")
                logging.info(f"  Size: {w}x{h} pixels")
                logging.info(f"  Width: {width_ratio:.1%} of image (gem check: {width_check_gem})")
                logging.info(f"  Height: {height_ratio:.1%} of image (gem check: {height_check_gem})")
                logging.info(f"  Aspect ratio: {aspect_ratio:.2f} (gem check: {aspect_check_gem})")
                logging.info(f"  Solidity: {solidity:.2f} (gem check: {solidity_check_gem})")
                logging.info(f"  Vertices: {num_vertices}")
                logging.info(f"  Category: {candidate['category']}")
                logging.info("")
            
            all_candidates.append(candidate)
            
            # Draw on debug image with ID number
            cv2.rectangle(debug_img, (x, y), (x+w, y+h), color, thickness)
            cv2.putText(debug_img, f"#{candidate_id}", (x+5, y+20),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
            
            # Add size info
            size_text = f"{w}x{h}"
            cv2.putText(debug_img, size_text, (x+5, y+40),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
            
            candidate_id += 1
        
        cv2.imwrite(f'{basename}_06_candidates_{name}.png', debug_img)
        logging.info(f"Saved candidates image for {name}")
    
    # Create comprehensive debug image with ALL candidates
    all_candidates_img = image.copy()
    
    # Sort by category for better visualization
    sorted_candidates = sorted(all_candidates, 
                              key=lambda x: ['EXCELLENT', 'GOOD', 'PARTIAL', 'POOR'].index(x['category']))
    
    for candidate in sorted_candidates:
        x, y, w, h = candidate['x'], candidate['y'], candidate['w'], candidate['h']
        
        if candidate['category'] == 'EXCELLENT':
            color = (0, 255, 0)
            thickness = 3
        elif candidate['category'] == 'GOOD':
            color = (0, 200, 255)
            thickness = 2
        elif candidate['category'] == 'PARTIAL':
            color = (255, 200, 0)
            thickness = 1
        else:
            continue  # Skip POOR in final image
        
        cv2.rectangle(all_candidates_img, (x, y), (x+w, y+h), color, thickness)
        cv2.putText(all_candidates_img, f"#{candidate['id']}", (x+5, y+20),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        
        # Add category label
        cv2.putText(all_candidates_img, candidate['category'], (x+5, y+h-5),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
    
    cv2.imwrite(f'{basename}_07_all_candidates.png', all_candidates_img)
    logging.info("Saved all candidates visualization")
    
    # Filter for final screens using gem-like criteria
    final_screens = []
    for candidate in sorted_candidates:
        if candidate['category'] in ['EXCELLENT', 'GOOD']:
            # Check for overlap with already selected screens
            overlap = False
            for screen in final_screens:
                # Calculate intersection
                x1 = max(candidate['x'], screen['x'])
                y1 = max(candidate['y'], screen['y'])
                x2 = min(candidate['x'] + candidate['w'], screen['x'] + screen['w'])
                y2 = min(candidate['y'] + candidate['h'], screen['y'] + screen['h'])
                
                if x2 > x1 and y2 > y1:  # There is intersection
                    intersection_area = (x2 - x1) * (y2 - y1)
                    min_area = min(candidate['w'] * candidate['h'], screen['w'] * screen['h'])
                    if intersection_area > 0.3 * min_area:
                        overlap = True
                        break
            
            if not overlap:
                final_screens.append(candidate)
                if len(final_screens) == 3:
                    break
    
    # Draw final result
    final_img = image.copy()
    for i, screen in enumerate(final_screens):
        x, y, w, h = screen['x'], screen['y'], screen['w'], screen['h']
        cv2.rectangle(final_img, (x, y), (x+w, y+h), (0, 255, 0), 3)
        cv2.putText(final_img, f"Screen {i+1}", (x, y-10),
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        # Save individual screen
        screen_roi = image[y:y+h, x:x+w]
        cv2.imwrite(f'{basename}_08_final_screen_{i+1}.png', screen_roi)
        
        logging.info(f"=== FINAL SCREEN {i+1} ===")
        logging.info(f"  Candidate ID: #{screen['id']}")
        logging.info(f"  Method: {screen['method']}")
        logging.info(f"  Position: ({x}, {y})")
        logging.info(f"  Size: {w}x{h}")
        logging.info(f"  Aspect ratio: {screen['aspect_ratio']:.2f}")
    
    cv2.imwrite(f'{basename}_08_final.png', final_img)
    
    # Create text summary
    with open('candidate_summary.txt', 'w') as f:
        f.write("=== ALL CANDIDATES SUMMARY ===\n\n")
        for candidate in sorted(all_candidates, key=lambda x: x['id']):
            f.write(f"ID #{candidate['id']} [{candidate['method']}]\n")
            f.write(f"  Position: ({candidate['x']}, {candidate['y']})\n")
            f.write(f"  Size: {candidate['w']}x{candidate['h']}\n")
            f.write(f"  Width ratio: {candidate['width_ratio']:.1%}\n")
            f.write(f"  Height ratio: {candidate['height_ratio']:.1%}\n")
            f.write(f"  Aspect ratio: {candidate['aspect_ratio']:.2f}\n")
            f.write(f"  Solidity: {candidate['solidity']:.2f}\n")
            f.write(f"  Category: {candidate['category']}\n")
            f.write("\n")
    
    logging.info(f"\n✅ Found {len(final_screens)} screens out of {len(all_candidates)} candidates")
    logging.info("Check output_claude_*.png files and candidate_summary.txt")
    
    return [(s['x'], s['y'], s['w'], s['h']) for s in final_screens]

# Main execution
if __name__ == "__main__":
    logging.info(f"=== Monitor Detection Log - {datetime.now()} ===\n")
    
    # Process the image
    input_image = argv[1]
    screens = find_screens_comprehensive(input_image)
    
    if screens:
        print(f"\n✅ SUCCESS: Detected {len(screens)} screens")
        for i, (x, y, w, h) in enumerate(screens):
            print(f"  Screen {i+1}: Position ({x}, {y}), Size {w}x{h}")
    else:
        print("\n❌ FAILED: No screens detected")
        print("Check claude_log.log and output_claude_*.png files for debugging")
